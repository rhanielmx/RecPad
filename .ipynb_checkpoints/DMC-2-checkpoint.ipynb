{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataset(dataset, trainRatio):\n",
    "    trainSize = int(len(dataset) * trainRatio)\n",
    "    trainSet = []\n",
    "    copy = list(dataset.iloc[:,:].values)\n",
    "    while len(trainSet) < trainSize:\n",
    "        index = random.randrange(len(copy))\n",
    "        trainSet.append(copy.pop(index))\n",
    "    return [np.array(trainSet), np.array(copy)]\n",
    "\n",
    "def calc_centroids(dataset, labels):\n",
    "    dataset=pd.DataFrame(dataset)\n",
    "    centroids=[]\n",
    "    for label in labels:\n",
    "        centroids.append((list((dataset[dataset['Target']==label].iloc[:,:-1]).sum()/len(dataset[dataset['Target']==label])),label))\n",
    "    return(centroids)\n",
    "\n",
    "def euc_distance(lista, x):\n",
    "    if(len(lista) == len(x)):\n",
    "        n=len(lista)-1\n",
    "    else:\n",
    "        return('Os conjuntos devem possuir a mesma dimensão!')\n",
    "    dist = 0\n",
    "    for i in range(n):\n",
    "        dist += (lista[i]-x[i])**2\n",
    "    return(np.sqrt(dist))\n",
    "\n",
    "def calc_distances(centroids, amostra):\n",
    "    distances=[]\n",
    "    for i in range(len(centroids)):\n",
    "        dist = euc_distance(centroids[i][0],amostra)\n",
    "        distances.append((dist,centroids[i][-1]))\n",
    "    return(distances)\n",
    "\n",
    "def att_class(centroids,amostra):\n",
    "    distances=calc_distances(centroids,amostra)\n",
    "    distances.sort()\n",
    "    return(distances[0][1])\n",
    "\n",
    "def make_pred(dataset,amostras):\n",
    "    labels = list(dataset.iloc[:,-1].unique())\n",
    "    centroids=calc_centroids(dataset, labels)\n",
    "    preds=[]\n",
    "    for amostra in amostras:\n",
    "        preds.append(att_class(centroids, amostra))\n",
    "    return(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_to_remove(dataset):\n",
    "    \"\"\"\n",
    "    Calcula algumas estatísticas para a remoção de outliers do dataset.\n",
    "    \n",
    "    Input\n",
    "    ----------\n",
    "    dataset: \n",
    "    Dataset a ser preparado para remoção de outliers.\n",
    "    \n",
    "    Output\n",
    "    ----------\n",
    "    cols:\n",
    "    Lista contendo os nomes das colunas dos datasets.\n",
    "  \n",
    "    means:\n",
    "    Lista contendo as médias das colunas dos datasets.\n",
    "  \n",
    "    stds:\n",
    "    Lista contendo os desios padrões das colunas dos datasets.\n",
    "  \n",
    "    \"\"\"\n",
    "    cols, means, stds = [],[],[]\n",
    "    for col in dataset.columns:\n",
    "        try:\n",
    "            cols.append(col)\n",
    "            means.append(dataset[col].mean())\n",
    "            stds.append(dataset[col].std())\n",
    "        except TypeError:\n",
    "            means.append(np.nan)\n",
    "            stds.append(np.nan)\n",
    "            print(f'Coluna {col} possui valores em formato não númerico!')\n",
    "    return(cols, means, stds)\n",
    "\n",
    "def remove_outliers(dataset):\n",
    "    \"\"\"\n",
    "    Soma todos os elementos de um vetor, exceto o que está na posição n.\n",
    "    \n",
    "    \n",
    "    Input\n",
    "    ----------\n",
    "    dataset: \n",
    "    Dataset para remoção de outliers.\n",
    "    \n",
    "    Output\n",
    "    ----------\n",
    "    dataset:\n",
    "    O dataset da entrada, agora com os outliers removidos\n",
    "    \n",
    "    \n",
    "    Obs.: São consideradas outliers da variável x, observações além do intervalo: mean(x) ± 2*std(x).\n",
    "    \"\"\"\n",
    "    cols, means, stds = prepare_to_remove(dataset)\n",
    "    k=0\n",
    "    for col in cols:\n",
    "        dataset = dataset.loc[(dataset[col] > means[k]-2*stds[k]) & (dataset[col] < means[k]+2*stds[k])]\n",
    "        k=k+1\n",
    "    return(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Average Importance(%)\n",
      "Exudates_Detection_1                     9.110714\n",
      "MA_Detection_alpha-0.5                   8.223888\n",
      "Exudates_Detection_2                     7.987080\n",
      "OpticDisc_Diameter                       7.615056\n",
      "Exudates_Detection_3                     7.408684\n",
      "Macula_OpticDisc_Distance                7.391314\n",
      "Exudates_Detection_4                     6.877441\n",
      "MA_Detection_alpha-0.6                   6.244501\n",
      "MA_Detection_alpha-0.7                   5.792654\n",
      "MA_Detection_alpha-0.9                   5.583021\n",
      "MA_Detection_alpha-1.0                   5.501992\n",
      "MA_Detection_alpha-0.8                   5.181421\n",
      "Exudates_Detection_5                     4.787482\n",
      "Exudates_Detection_7                     4.523325\n",
      "Exudates_Detection_6                     3.853383\n",
      "Exudates_Detection_8                     2.958127\n",
      "AM/FM-based classification               0.959918\n",
      "Pre-Screening                            0.000000\n",
      "Quality_Assessment                       0.000000\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('https://raw.githubusercontent.com/rhanielmx/RecPad/master/messidor_features.csv')\n",
    "data=remove_outliers(data)\n",
    "feature_importances=[]\n",
    "cols_names=[]\n",
    "for i in range(50):\n",
    "    train_set, test_set = splitDataset(dataset=data,trainRatio=0.7)\n",
    "    X_train,y_train=[train_set[i][:-1] for i in range(train_set.shape[0])],[train_set[i][-1] for i in range(train_set.shape[0])]\n",
    "    X_test,y_test=[test_set[i][:-1] for i in range(test_set.shape[0])],[test_set[i][-1] for i in range(test_set.shape[0])]\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier \n",
    "    rf = RandomForestClassifier() \n",
    "    rf.fit(X_train, y_train) \n",
    "\n",
    "    feature_importances.append(rf.feature_importances_)\n",
    "\n",
    "avg_feature_importances=sum(feature_importances)/len(feature_importances)\n",
    "avg_feature_importances=pd.DataFrame(avg_feature_importances*100,columns=['Average Importance(%)'],index=list(data.columns[:-1]))\n",
    "\n",
    "print(avg_feature_importances.sort_values('Average Importance(%)',ascending=False))\n",
    "cols_to_use=[avg_feature_importances.index[i] for i in range(len(avg_feature_importances.index)) if (avg_feature_importances.iloc[i,0]>=(avg_feature_importances).mean()[0])==True]\n",
    "cols_to_use.append('Target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():    \n",
    "    for _ in range(n_rounds):\n",
    "        data=pd.read_csv(filepath_or_buffer=path,usecols=cols_to_use)\n",
    "        data=remove_outliers(data)\n",
    "        \n",
    "        train_set, test_set = splitDataset(dataset=data,trainRatio=trainRatio)\n",
    "        X_test=[test_set[i][:-1] for i in range(test_set.shape[0])]\n",
    "        y_test=[test_set[i][-1] for i in range(test_set.shape[0])]\n",
    "\n",
    "        preds=make_pred(data,np.array(X_test))\n",
    "        \n",
    "        cm = confusion_matrix(y_test, preds)\n",
    "        sr = 100*(cm.diagonal().sum()/cm.sum())\n",
    "        confusion_matrixes.append(cm)\n",
    "        accuracys.append(sr)        \n",
    "        \n",
    "        class0_success=100*cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "        class1_success=100*cm[1][1]/(cm[1][0]+cm[1][1])\n",
    "         \n",
    "        class0_successes.append(class0_success)\n",
    "        class1_successes.append(class1_success)\n",
    "    \n",
    "        if ((_+1)%(int(n_rounds/10))==0):\n",
    "            print(f'{(_+1)*(100/n_rounds):05.2f}% concluído!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.00% concluído!\n",
      "20.00% concluído!\n",
      "30.00% concluído!\n",
      "40.00% concluído!\n",
      "50.00% concluído!\n",
      "60.00% concluído!\n",
      "70.00% concluído!\n",
      "80.00% concluído!\n",
      "90.00% concluído!\n",
      "100.00% concluído!\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "accuracys = []\n",
    "confusion_matrixes = []\n",
    "class0_successes,class1_successes=[],[]\n",
    "trainRatio=0.7\n",
    "n_rounds=100\n",
    "path='https://raw.githubusercontent.com/rhanielmx/RecPad/master/messidor_features.csv'\n",
    "\n",
    "%time main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>55.286232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.245972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>49.275362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>53.985507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.434783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>56.884058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>61.594203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracys\n",
       "count  100.000000\n",
       "mean    55.286232\n",
       "std      2.245972\n",
       "min     49.275362\n",
       "25%     53.985507\n",
       "50%     55.434783\n",
       "75%     56.884058\n",
       "max     61.594203"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracys=pd.DataFrame(data={'Accuracys':accuracys})\n",
    "Accuracys.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Succces 0</th>\n",
       "      <th>Succces 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>56.988057</td>\n",
       "      <td>53.532724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.188954</td>\n",
       "      <td>3.368860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>48.507463</td>\n",
       "      <td>46.323529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>55.007562</td>\n",
       "      <td>51.384132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.896880</td>\n",
       "      <td>53.504749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>59.027778</td>\n",
       "      <td>56.101948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>66.165414</td>\n",
       "      <td>62.015504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Succces 0   Succces 1\n",
       "count  100.000000  100.000000\n",
       "mean    56.988057   53.532724\n",
       "std      3.188954    3.368860\n",
       "min     48.507463   46.323529\n",
       "25%     55.007562   51.384132\n",
       "50%     56.896880   53.504749\n",
       "75%     59.027778   56.101948\n",
       "max     66.165414   62.015504"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Class_Sucesses=pd.DataFrame(data={'Succces 0':class0_successes,'Succces 1':class1_successes})\n",
    "Class_Sucesses.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
