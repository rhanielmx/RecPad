{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataset(dataset, trainRatio):\n",
    "    trainSize = int(len(dataset) * trainRatio)\n",
    "    trainSet = []\n",
    "    copy = list(dataset.iloc[:,:].values)\n",
    "    while len(trainSet) < trainSize:\n",
    "        index = random.randrange(len(copy))\n",
    "        trainSet.append(copy.pop(index))\n",
    "    return [np.array(trainSet), np.array(copy)]\n",
    "\n",
    "def euc_distance(lista, x):\n",
    "    if(len(lista) == len(x)):\n",
    "        n=len(lista)-1\n",
    "    else:\n",
    "        return('Os conjuntos devem possuir a mesma dimensão!')\n",
    "    dist = 0\n",
    "    for i in range(n):\n",
    "        dist += (lista[i]-x[i])**2\n",
    "    return(np.sqrt(dist))\n",
    "\n",
    "def calc_distances(train_set, amostra):\n",
    "    distances=[]\n",
    "    for i in range(len(train_set)):\n",
    "        dist = euc_distance(train_set[i],amostra)\n",
    "        distances.append((dist,train_set[i][-1]))\n",
    "    return(distances)\n",
    "\n",
    "def att_class(dataset,amostra):\n",
    "    distances=calc_distances(dataset,amostra)\n",
    "    distances.sort()\n",
    "    return(distances[0][1])\n",
    "\n",
    "def make_pred(dataset,amostras):\n",
    "    preds=[]\n",
    "    for amostra in amostras:\n",
    "        preds.append(att_class(dataset, amostra))\n",
    "    return(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_to_remove(dataset):\n",
    "    \"\"\"\n",
    "    Calcula algumas estatísticas para a remoção de outliers do dataset.\n",
    "    \n",
    "    Input\n",
    "    ----------\n",
    "    dataset: \n",
    "    Dataset a ser preparado para remoção de outliers.\n",
    "    \n",
    "    Output\n",
    "    ----------\n",
    "    cols:\n",
    "    Lista contendo os nomes das colunas dos datasets.\n",
    "  \n",
    "    means:\n",
    "    Lista contendo as médias das colunas dos datasets.\n",
    "  \n",
    "    stds:\n",
    "    Lista contendo os desios padrões das colunas dos datasets.\n",
    "  \n",
    "    \"\"\"\n",
    "    cols, means, stds = [],[],[]\n",
    "    for col in dataset.columns:\n",
    "        try:\n",
    "            cols.append(col)\n",
    "            means.append(dataset[col].mean())\n",
    "            stds.append(dataset[col].std())\n",
    "        except TypeError:\n",
    "            means.append(np.nan)\n",
    "            stds.append(np.nan)\n",
    "            print(f'Coluna {col} possui valores em formato não númerico!')\n",
    "    return(cols, means, stds)\n",
    "\n",
    "def remove_outliers(dataset):\n",
    "    \"\"\"\n",
    "    Soma todos os elementos de um vetor, exceto o que está na posição n.\n",
    "    \n",
    "    Input\n",
    "    ----------\n",
    "    dataset: \n",
    "    Dataset para remoção de outliers.\n",
    "    \n",
    "    Output\n",
    "    ----------\n",
    "    dataset:\n",
    "    O dataset da entrada, agora com os outliers removidos\n",
    "    \n",
    "    \n",
    "    Obs.: São consideradas outliers da variável x, observações além do intervalo: mean(x) ± 2*std(x).\n",
    "    \"\"\"\n",
    "    cols, means, stds = prepare_to_remove(dataset)\n",
    "    k=0\n",
    "    for col in cols:\n",
    "        dataset = dataset.loc[(dataset[col] > means[k]-2*stds[k]) & (dataset[col] < means[k]+2*stds[k])]\n",
    "        k=k+1\n",
    "    return(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Average Importance(%)\n",
      "Exudates_Detection_1                     9.094294\n",
      "MA_Detection_alpha-0.5                   8.167433\n",
      "Exudates_Detection_2                     7.872369\n",
      "Macula_OpticDisc_Distance                7.805295\n",
      "OpticDisc_Diameter                       7.754035\n",
      "Exudates_Detection_3                     7.189910\n",
      "Exudates_Detection_4                     6.967984\n",
      "MA_Detection_alpha-0.6                   6.085020\n",
      "MA_Detection_alpha-0.7                   5.708789\n",
      "MA_Detection_alpha-1.0                   5.545903\n",
      "MA_Detection_alpha-0.9                   5.472036\n",
      "MA_Detection_alpha-0.8                   5.242609\n",
      "Exudates_Detection_5                     4.772039\n",
      "Exudates_Detection_7                     4.743409\n",
      "Exudates_Detection_6                     3.647565\n",
      "Exudates_Detection_8                     3.007950\n",
      "AM/FM-based classification               0.923362\n",
      "Pre-Screening                            0.000000\n",
      "Quality_Assessment                       0.000000\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('https://raw.githubusercontent.com/rhanielmx/RecPad/master/messidor_features.csv')\n",
    "data=remove_outliers(data)\n",
    "feature_importances=[]\n",
    "cols_names=[]\n",
    "for i in range(50):\n",
    "    train_set, test_set = splitDataset(dataset=data,trainRatio=0.7)\n",
    "    X_train,y_train=[train_set[i][:-1] for i in range(train_set.shape[0])],[train_set[i][-1] for i in range(train_set.shape[0])]\n",
    "    X_test,y_test=[test_set[i][:-1] for i in range(test_set.shape[0])],[test_set[i][-1] for i in range(test_set.shape[0])]\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier \n",
    "    rf = RandomForestClassifier() \n",
    "    rf.fit(X_train, y_train) \n",
    "\n",
    "    feature_importances.append(rf.feature_importances_)\n",
    "\n",
    "avg_feature_importances=sum(feature_importances)/len(feature_importances)\n",
    "avg_feature_importances=pd.DataFrame(avg_feature_importances*100,columns=['Average Importance(%)'],index=list(data.columns[:-1]))\n",
    "\n",
    "print(avg_feature_importances.sort_values('Average Importance(%)',ascending=False))\n",
    "cols_to_use=[avg_feature_importances.index[i] for i in range(len(avg_feature_importances.index)) if (avg_feature_importances.iloc[i,0]>=(avg_feature_importances).mean()[0])==True]\n",
    "cols_to_use.append('Target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():    \n",
    "    for _ in range(n_rounds):\n",
    "        data=pd.read_csv(filepath_or_buffer=path,usecols=cols_to_use)\n",
    "        data=remove_outliers(data)\n",
    "        train_set, test_set = splitDataset(dataset=data,trainRatio=trainRatio)\n",
    "        y_test=[test_set[i][-1] for i in range(test_set.shape[0])]\n",
    "        \n",
    "        preds=make_pred(train_set, test_set)\n",
    "        \n",
    "        \n",
    "        cm = confusion_matrix(y_test, preds)\n",
    "        sr = 100*(cm.diagonal().sum()/cm.sum())\n",
    "        confusion_matrixes.append(cm)\n",
    "        accuracys.append(sr)\n",
    "        \n",
    "        class0_success=100*cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "        class1_success=100*cm[1][1]/(cm[1][0]+cm[1][1])\n",
    "         \n",
    "        class0_successes.append(class0_success)\n",
    "        class1_successes.append(class1_success)\n",
    "        \n",
    "        if ((_+1)%(int(n_rounds/10))==0):\n",
    "            print(f'{(_+1)*(100/n_rounds):05.2f}% concluído!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.00% concluído!\n",
      "20.00% concluído!\n",
      "30.00% concluído!\n",
      "40.00% concluído!\n",
      "50.00% concluído!\n",
      "60.00% concluído!\n",
      "70.00% concluído!\n",
      "80.00% concluído!\n",
      "90.00% concluído!\n",
      "100.00% concluído!\n",
      "Wall time: 5min 37s\n"
     ]
    }
   ],
   "source": [
    "accuracys = []\n",
    "confusion_matrixes = []\n",
    "class0_successes,class1_successes=[],[]\n",
    "trainRatio=0.7\n",
    "n_rounds=100\n",
    "path='https://raw.githubusercontent.com/rhanielmx/RecPad/master/messidor_features.csv'\n",
    "\n",
    "%time main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>60.184783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.647954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>54.347826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>58.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>60.326087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>62.047101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>65.942029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracys\n",
       "count  100.000000\n",
       "mean    60.184783\n",
       "std      2.647954\n",
       "min     54.347826\n",
       "25%     58.333333\n",
       "50%     60.326087\n",
       "75%     62.047101\n",
       "max     65.942029"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracys=pd.DataFrame(data={'Accuracys':accuracys})\n",
    "Accuracys.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Succces 0</th>\n",
       "      <th>Succces 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>61.811406</td>\n",
       "      <td>58.588029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.849646</td>\n",
       "      <td>4.250281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>54.140127</td>\n",
       "      <td>49.659864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>59.321429</td>\n",
       "      <td>55.823055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>61.444077</td>\n",
       "      <td>58.866925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>64.613971</td>\n",
       "      <td>61.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>70.370370</td>\n",
       "      <td>69.421488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Succces 0   Succces 1\n",
       "count  100.000000  100.000000\n",
       "mean    61.811406   58.588029\n",
       "std      3.849646    4.250281\n",
       "min     54.140127   49.659864\n",
       "25%     59.321429   55.823055\n",
       "50%     61.444077   58.866925\n",
       "75%     64.613971   61.363636\n",
       "max     70.370370   69.421488"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Class_Sucesses=pd.DataFrame(data={'Succces 0':class0_successes,'Succces 1':class1_successes})\n",
    "Class_Sucesses.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
